{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29ekoHpBCoKe",
    "outputId": "9d0e34d4-1b81-4e50-d7e3-353d0cdfee63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chess\n",
      "  Downloading chess-1.11.1.tar.gz (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: chess\n",
      "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for chess: filename=chess-1.11.1-py3-none-any.whl size=148497 sha256=d9a03b629e9b9a68d382e4e43ff321cb49286fe6c5153c9b6ebfb610d341ae3e\n",
      "  Stored in directory: /root/.cache/pip/wheels/2e/2d/23/1bfc95db984ed3ecbf6764167dc7526d0ab521cf9a9852544e\n",
      "Successfully built chess\n",
      "Installing collected packages: chess\n",
      "Successfully installed chess-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install chess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G314LoRgNUn"
   },
   "source": [
    "# Part 1: Load Data\n",
    "\n",
    "Our raw data contains the details of a singular chess game. Our focus is on the move sequence (which we would use to construct game states) and player information (ELO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pDGf1u13uHs",
    "outputId": "1cd76ef0-b3f9-402d-de42-7a83ff881af6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file loaded successfully with 20058 rows.\n",
      "         id  rated    created_at  last_move_at  turns victory_status winner  \\\n",
      "0  TZJHLljE  False  1.500000e+12  1.500000e+12     13      outoftime  white   \n",
      "1  l1NXvwaE   True  1.500000e+12  1.500000e+12     16         resign  black   \n",
      "2  mIICvQHh   True  1.500000e+12  1.500000e+12     61           mate  white   \n",
      "3  kWKvrqYL   True  1.500000e+12  1.500000e+12     61           mate  white   \n",
      "4  9tXo1AUZ   True  1.500000e+12  1.500000e+12     95           mate  white   \n",
      "\n",
      "  increment_code       white_id  white_rating      black_id  black_rating  \\\n",
      "0           15+2       bourgris          1500          a-00          1191   \n",
      "1           5+10           a-00          1322     skinnerua          1261   \n",
      "2           5+10         ischia          1496          a-00          1500   \n",
      "3           20+0  daniamurashov          1439  adivanov2009          1454   \n",
      "4           30+3      nik221107          1523  adivanov2009          1469   \n",
      "\n",
      "                                               moves opening_eco  \\\n",
      "0  d4 d5 c4 c6 cxd5 e6 dxe6 fxe6 Nf3 Bb4+ Nc3 Ba5...         D10   \n",
      "1  d4 Nc6 e4 e5 f4 f6 dxe5 fxe5 fxe5 Nxe5 Qd4 Nc6...         B00   \n",
      "2  e4 e5 d3 d6 Be3 c6 Be2 b5 Nd2 a5 a4 c5 axb5 Nc...         C20   \n",
      "3  d4 d5 Nf3 Bf5 Nc3 Nf6 Bf4 Ng4 e3 Nc6 Be2 Qd7 O...         D02   \n",
      "4  e4 e5 Nf3 d6 d4 Nc6 d5 Nb4 a3 Na6 Nc3 Be7 b4 N...         C41   \n",
      "\n",
      "                             opening_name  opening_ply  \n",
      "0        Slav Defense: Exchange Variation            5  \n",
      "1  Nimzowitsch Defense: Kennedy Variation            4  \n",
      "2   King's Pawn Game: Leonardis Variation            3  \n",
      "3  Queen's Pawn Game: Zukertort Variation            3  \n",
      "4                        Philidor Defense            5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chess\n",
    "\n",
    "def load_chess_data(filepath, nrows=None):\n",
    "    \"\"\"\n",
    "    Load chess game data from a CSV file into a Pandas DataFrame. By default, the entire file is loaded.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): The path to the CSV file.\n",
    "        nrows (int, optional): The number of rows to load. If None, the entire file is loaded.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded DataFrame containing the chess data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file, either all rows or the first nrows rows\n",
    "        df = pd.read_csv(filepath, nrows=nrows)\n",
    "\n",
    "        # Ensure required columns are present\n",
    "        required_columns = ['winner', 'white_rating', 'black_rating', 'moves',\n",
    "                            'opening_eco', 'opening_name', 'opening_ply']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Missing required columns in the CSV file: {missing_columns}\")\n",
    "\n",
    "        print(f\"CSV file loaded successfully with {len(df)} rows.\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the entire CSV file or specify the number of rows\n",
    "file_path = \"games.csv\"\n",
    "chess_df = load_chess_data(file_path)\n",
    "\n",
    "if chess_df is not None:\n",
    "    print(chess_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9XT-IRmge95"
   },
   "source": [
    "# Part 2: Game State Construction and Data Engineering\n",
    "\n",
    "We want to make a prediction of a winner (white win percentage) based on a particular board state. To extract the board states, we extract every single board state from each game, using the sequences of moves.\n",
    "\n",
    "We then calculate certain parameters from the game state and save all individual game states. The details are as follows. All differential values are (WHITE - BLACK).\n",
    "\n",
    "### Piece Differential\n",
    "Each remaining piece gets assigned a standard weight:\n",
    "- PAWN: 1\n",
    "- KNIGHT: 3\n",
    "- BISHOP: 3\n",
    "- ROOK: 5\n",
    "- QUEEN: 9\n",
    "- KING: 0 (as all states must have a king)\n",
    "The differntial is calculated by white's piece value minus that of black.\n",
    "\n",
    "### ELO Differential\n",
    "Difference of ELO rating.\n",
    "\n",
    "### Mobility\n",
    "Difference in number of legal moves. \n",
    "\n",
    "### King Safety\n",
    "Points are added for certain pawn sheild structures around the king, and are subtracted if less of these pawns exist. Return the difference between players.\n",
    "\n",
    "### Game Phase\n",
    "Return the game phase (opening, midgame, endgame) based on move number and remaining pieces. \n",
    "\n",
    "### Pawn Structure\n",
    "Two types of pawn structures are evaluated:\n",
    "- Isolated pawns\n",
    "- Doubled pawns\n",
    "Differential is calculated between white and black, and returned. \n",
    "\n",
    "### Control of Key Squares\n",
    "Bonus points for controlling crucial middle section squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rW6NSYkhF2NQ"
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_piece_differential(board):\n",
    "    piece_values = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 9,\n",
    "        chess.KING: 0  # Assign 0 value to the King\n",
    "    }\n",
    "    white_value = sum(\n",
    "        piece_values.get(piece.piece_type, 0)\n",
    "        for piece in board.piece_map().values()\n",
    "        if piece.color == chess.WHITE\n",
    "    )\n",
    "    black_value = sum(\n",
    "        piece_values.get(piece.piece_type, 0)\n",
    "        for piece in board.piece_map().values()\n",
    "        if piece.color == chess.BLACK\n",
    "    )\n",
    "    return white_value - black_value\n",
    "\n",
    "def calculate_elo_diff(df):\n",
    "    \"\"\"\n",
    "    Calculate the Elo difference (white_rating - black_rating).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The chess dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated DataFrame with the 'elo_diff' column.\n",
    "    \"\"\"\n",
    "    df['elo_diff'] = df['white_rating'] - df['black_rating']\n",
    "    return df\n",
    "\n",
    "def calculate_mobility(board):\n",
    "    \"\"\"\n",
    "    Calculate the mobility difference (white_moves - black_moves).\n",
    "\n",
    "    Args:\n",
    "        board (chess.Board): The current game state.\n",
    "\n",
    "    Returns:\n",
    "        int: The difference in the number of legal moves.\n",
    "    \"\"\"\n",
    "    original_turn = board.turn\n",
    "    board.turn = chess.WHITE\n",
    "    white_moves = len(list(board.legal_moves))\n",
    "    board.turn = chess.BLACK\n",
    "    black_moves = len(list(board.legal_moves))\n",
    "    board.turn = original_turn  # Restore the original turn\n",
    "    return white_moves - black_moves\n",
    "\n",
    "def calculate_king_safety(board):\n",
    "    \"\"\"\n",
    "    Calculate the king safety differential.\n",
    "\n",
    "    Args:\n",
    "        board (chess.Board): The current game state.\n",
    "\n",
    "    Returns:\n",
    "        float: The difference in king safety scores (white - black).\n",
    "    \"\"\"\n",
    "    def king_safety_for_color(color):\n",
    "        king_square = board.king(color)\n",
    "        safety_score = 0\n",
    "\n",
    "        # Check if the king is castled\n",
    "        if color == chess.WHITE:\n",
    "            if king_square == chess.E1:\n",
    "                safety_score -= 1  # Less safe if not castled\n",
    "            elif king_square in [chess.G1, chess.C1]:\n",
    "                safety_score += 1  # More safe if castled\n",
    "        else:\n",
    "            if king_square == chess.E8:\n",
    "                safety_score -= 1\n",
    "            elif king_square in [chess.G8, chess.C8]:\n",
    "                safety_score += 1\n",
    "\n",
    "        # Check for pawn shield around the king\n",
    "        pawn_shield_squares = []\n",
    "        if color == chess.WHITE:\n",
    "            if king_square == chess.G1:\n",
    "                pawn_shield_squares = [chess.F2, chess.G2, chess.H2]\n",
    "            elif king_square == chess.C1:\n",
    "                pawn_shield_squares = [chess.A2, chess.B2, chess.C2]\n",
    "            else:\n",
    "                pawn_shield_squares = [chess.D2, chess.E2, chess.F2]\n",
    "        else:\n",
    "            if king_square == chess.G8:\n",
    "                pawn_shield_squares = [chess.F7, chess.G7, chess.H7]\n",
    "            elif king_square == chess.C8:\n",
    "                pawn_shield_squares = [chess.A7, chess.B7, chess.C7]\n",
    "            else:\n",
    "                pawn_shield_squares = [chess.D7, chess.E7, chess.F7]\n",
    "\n",
    "        for square in pawn_shield_squares:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece and piece.piece_type == chess.PAWN and piece.color == color:\n",
    "                safety_score += 0.5\n",
    "            else:\n",
    "                safety_score -= 0.5\n",
    "\n",
    "        return safety_score\n",
    "\n",
    "    white_king_safety = king_safety_for_color(chess.WHITE)\n",
    "    black_king_safety = king_safety_for_color(chess.BLACK)\n",
    "    return white_king_safety - black_king_safety\n",
    "\n",
    "def get_game_phase(turn_number):\n",
    "    \"\"\"\n",
    "    Determine the game phase based on the turn number.\n",
    "\n",
    "    Args:\n",
    "        turn_number (int): The current turn number.\n",
    "\n",
    "    Returns:\n",
    "        dict: One-hot encoded game phase.\n",
    "    \"\"\"\n",
    "    if turn_number <= 15:\n",
    "        return {'opening': 1, 'middle_game': 0, 'endgame': 0}\n",
    "    elif turn_number <= 40:\n",
    "        return {'opening': 0, 'middle_game': 1, 'endgame': 0}\n",
    "    else:\n",
    "        return {'opening': 0, 'middle_game': 0, 'endgame': 1}\n",
    "\n",
    "def calculate_pawn_structure(board):\n",
    "    \"\"\"\n",
    "    Calculate pawn structure metrics like doubled and isolated pawns.\n",
    "\n",
    "    Args:\n",
    "        board (chess.Board): The current game state.\n",
    "\n",
    "    Returns:\n",
    "        dict: Differences in pawn structure metrics (white - black).\n",
    "    \"\"\"\n",
    "    def pawn_structure_for_color(color):\n",
    "        pawns = board.pieces(chess.PAWN, color)\n",
    "        files_with_pawns = [chess.square_file(square) for square in pawns]\n",
    "        file_counts = Counter(files_with_pawns)\n",
    "\n",
    "        # Doubled pawns: files with more than one pawn\n",
    "        doubled_pawns = sum(1 for count in file_counts.values() if count > 1)\n",
    "\n",
    "        # Isolated pawns: pawns with no friendly pawns on adjacent files\n",
    "        isolated_pawns = 0\n",
    "        for file in file_counts:\n",
    "            adjacent_files = [file - 1, file + 1]\n",
    "            has_adjacent_pawn = any(\n",
    "                adj_file in file_counts for adj_file in adjacent_files if 0 <= adj_file <= 7\n",
    "            )\n",
    "            if not has_adjacent_pawn:\n",
    "                isolated_pawns += file_counts[file]\n",
    "\n",
    "        return {'doubled_pawns': doubled_pawns, 'isolated_pawns': isolated_pawns}\n",
    "\n",
    "    white_pawn_structure = pawn_structure_for_color(chess.WHITE)\n",
    "    black_pawn_structure = pawn_structure_for_color(chess.BLACK)\n",
    "\n",
    "    pawn_structure_diff = {\n",
    "        'doubled_pawns_diff': white_pawn_structure['doubled_pawns'] - black_pawn_structure['doubled_pawns'],\n",
    "        'isolated_pawns_diff': white_pawn_structure['isolated_pawns'] - black_pawn_structure['isolated_pawns']\n",
    "    }\n",
    "    return pawn_structure_diff\n",
    "\n",
    "def calculate_control_of_key_squares(board):\n",
    "    \"\"\"\n",
    "    Calculate the difference in control of key squares.\n",
    "\n",
    "    Args:\n",
    "        board (chess.Board): The current game state.\n",
    "\n",
    "    Returns:\n",
    "        int: Difference in control of key squares (white - black).\n",
    "    \"\"\"\n",
    "    key_squares = [chess.E4, chess.D4, chess.E5, chess.D5]\n",
    "    white_control = sum(1 for square in key_squares if board.is_attacked_by(chess.WHITE, square))\n",
    "    black_control = sum(1 for square in key_squares if board.is_attacked_by(chess.BLACK, square))\n",
    "    return white_control - black_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ndCkmaTUH3Io"
   },
   "outputs": [],
   "source": [
    "def split_game_into_states(df):\n",
    "    \"\"\"\n",
    "    Split games into states and calculate state-level features, including the target variable y.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The chess dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with game states and their features.\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    total_games = len(df)\n",
    "    print(f\"Processing {total_games} games...\")\n",
    "\n",
    "    # Use tqdm to wrap the iterator for the progress bar\n",
    "    for index, row in tqdm(df.iterrows(), total=total_games, desc=\"Processing games\"):\n",
    "        game_id = row.get('id', index)\n",
    "        moves_str = row['moves']\n",
    "        elo_diff = row['elo_diff']\n",
    "        winner = row['winner']\n",
    "\n",
    "        # Remove move numbers and annotations\n",
    "        moves_str = re.sub(r'\\d+\\.', '', moves_str)\n",
    "        moves_str = re.sub(r'\\{[^}]*\\}', '', moves_str)\n",
    "        moves_str = moves_str.strip()\n",
    "        moves = moves_str.split()\n",
    "\n",
    "        total_turns = len(moves)  # Total number of moves in the game\n",
    "\n",
    "        board = chess.Board()\n",
    "        for turn_number, move in enumerate(moves, start=1):\n",
    "            try:\n",
    "                board.push_san(move)\n",
    "                fen = board.fen()\n",
    "                piece_diff = calculate_piece_differential(board)\n",
    "\n",
    "                # Calculate additional features\n",
    "                mobility = calculate_mobility(board)\n",
    "                king_safety = calculate_king_safety(board)\n",
    "                game_phase = get_game_phase(turn_number)\n",
    "                pawn_structure = calculate_pawn_structure(board)\n",
    "                control_of_key_squares = calculate_control_of_key_squares(board)\n",
    "\n",
    "                # Calculate the target variable y\n",
    "                if winner == 'white':\n",
    "                    y = 0.5 + 0.5 * (turn_number / total_turns)\n",
    "                elif winner == 'black':\n",
    "                    y = 0.5 - 0.5 * (turn_number / total_turns)\n",
    "                else:  # For draws or other outcomes\n",
    "                    y = 0.5\n",
    "\n",
    "                state = {\n",
    "                    # 'game_id': game_id,\n",
    "                    'turn_number': turn_number,\n",
    "                    'fen': fen,\n",
    "                    'piece_diff': piece_diff,\n",
    "                    'elo_diff': elo_diff,\n",
    "                    'mobility': mobility,\n",
    "                    'king_safety': king_safety,\n",
    "                    'control_of_key_squares': control_of_key_squares,\n",
    "                    'winner': winner,\n",
    "                    'y': y  # Add the target variable\n",
    "                }\n",
    "                # Merge game_phase and pawn_structure into the state\n",
    "                state.update(game_phase)\n",
    "                state.update(pawn_structure)\n",
    "                states.append(state)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing move '{move}' in game {game_id}: {type(e).__name__}: {e}\")\n",
    "                break\n",
    "    return pd.DataFrame(states)\n",
    "\n",
    "def process_chess_data(df):\n",
    "    \"\"\"\n",
    "    Process the chess data to calculate game and state-level features.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The chess dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with game states and their features.\n",
    "    \"\"\"\n",
    "    df = calculate_elo_diff(df)\n",
    "    game_states = split_game_into_states(df)\n",
    "    return game_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJuqrAtxGFDa",
    "outputId": "850c0562-4757-442f-bc75-e7ef11ed1c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20058 games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games: 100%|██████████| 20058/20058 [10:27<00:00, 31.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed game states saved to processed_game_states.csv\n",
      "   turn_number                                                fen  piece_diff  \\\n",
      "0            1  rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR ...           0   \n",
      "1            2  rnbqkbnr/ppp1pppp/8/3p4/3P4/8/PPP1PPPP/RNBQKBN...           0   \n",
      "2            3  rnbqkbnr/ppp1pppp/8/3p4/2PP4/8/PP2PPPP/RNBQKBN...           0   \n",
      "3            4  rnbqkbnr/pp2pppp/2p5/3p4/2PP4/8/PP2PPPP/RNBQKB...           0   \n",
      "4            5  rnbqkbnr/pp2pppp/2p5/3P4/3P4/8/PP2PPPP/RNBQKBN...           1   \n",
      "\n",
      "   elo_diff  mobility  king_safety  control_of_key_squares winner         y  \\\n",
      "0       309         8         -1.0                       2  white  0.538462   \n",
      "1       309         0          0.0                       0  white  0.576923   \n",
      "2       309         2          0.0                       1  white  0.615385   \n",
      "3       309         1          0.0                       1  white  0.653846   \n",
      "4       309         0          0.0                       1  white  0.692308   \n",
      "\n",
      "   opening  middle_game  endgame  doubled_pawns_diff  isolated_pawns_diff  \n",
      "0        1            0        0                   0                    0  \n",
      "1        1            0        0                   0                    0  \n",
      "2        1            0        0                   0                    0  \n",
      "3        1            0        0                   0                    0  \n",
      "4        1            0        0                   1                    0  \n"
     ]
    }
   ],
   "source": [
    "if chess_df is not None:\n",
    "    # Process the data\n",
    "    game_states = process_chess_data(chess_df)\n",
    "\n",
    "    # Save or inspect the results\n",
    "    output_file = \"processed_game_states.csv\"\n",
    "    game_states.to_csv(output_file, index=False)\n",
    "    print(f\"Processed game states saved to {output_file}\")\n",
    "    print(game_states.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5DofSEng6f6"
   },
   "source": [
    "# Part 3: Train the model\n",
    "\n",
    "We use our own CNN model to train the data. We first transform the board into a tensor, then normalize the above parameters to enhance the CNN structure. \n",
    "\n",
    "### Output Data\n",
    "One of the main problems with our idea is that we don't have a definitive prediction of a game's win probability status for every single game state - we are only given the eventual winner for training. Thus, after research and experimenting, we devised a formula, mostly linear, based on the final win party and game state, to assign a win probability to each state. Our model is now aimed to produce this prediction based on the above parameters with no knowledge of the winner.\n",
    "\n",
    "The training history is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1212827 game states.\n",
      "Converting FEN to tensors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1212827/1212827 [00:15<00:00, 77094.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# Load processed game states DataFrame\n",
    "game_states = pd.read_csv(\"processed_game_states.csv\")\n",
    "print(f\"Loaded {len(game_states)} game states.\")\n",
    "\n",
    "# Function to convert FEN to tensor\n",
    "def fen_to_tensor(fen):\n",
    "    piece_to_index = {\n",
    "        'P': 0,  'N': 1,  'B': 2,  'R': 3,  'Q': 4,  'K': 5,\n",
    "        'p': 6,  'n': 7,  'b': 8,  'r': 9,  'q': 10, 'k': 11\n",
    "    }\n",
    "    board_tensor = np.zeros((8, 8, 12), dtype=int)\n",
    "    fen_board = fen.split(' ')[0]\n",
    "    rows = fen_board.split('/')\n",
    "    for row_idx, row in enumerate(rows):\n",
    "        col_idx = 0\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                col_idx += int(char)\n",
    "            else:\n",
    "                piece_idx = piece_to_index[char]\n",
    "                board_tensor[row_idx, col_idx, piece_idx] = 1\n",
    "                col_idx += 1\n",
    "    return board_tensor\n",
    "\n",
    "# Convert FEN to tensors\n",
    "print(\"Converting FEN to tensors...\")\n",
    "tqdm.pandas()\n",
    "board_tensors = game_states['fen'].progress_apply(fen_to_tensor)\n",
    "X_board = np.stack(board_tensors.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmswprK8Sx8p",
    "outputId": "be451fe8-90b2-4278-efb9-eb9f0dbe0d5d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 00:36:12.018636: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-26 00:36:12.726575: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-26 00:36:20.816807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1636] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30871 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:18:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 00:36:28.999753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8904\n",
      "2024-11-26 00:36:29.776132: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fc88c73dd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-11-26 00:36:29.776160: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-11-26 00:36:29.881684: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-26 00:36:30.706849: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30321/30321 [==============================] - ETA: 0s - loss: 0.0439 - mean_squared_error: 0.0439 - mean_absolute_error: 0.1570\n",
      "New best model saved at epoch 1 with val_loss: 0.0328\n",
      "30321/30321 [==============================] - 119s 4ms/step - loss: 0.0439 - mean_squared_error: 0.0439 - mean_absolute_error: 0.1570 - val_loss: 0.0328 - val_mean_squared_error: 0.0328 - val_mean_absolute_error: 0.1316\n",
      "Epoch 2/100\n",
      "   33/30321 [..............................] - ETA: 1:39 - loss: 0.0322 - mean_squared_error: 0.0322 - mean_absolute_error: 0.1312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30321/30321 [==============================] - ETA: 0s - loss: 0.0280 - mean_squared_error: 0.0280 - mean_absolute_error: 0.1215\n",
      "New best model saved at epoch 2 with val_loss: 0.0232\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0280 - mean_squared_error: 0.0280 - mean_absolute_error: 0.1215 - val_loss: 0.0232 - val_mean_squared_error: 0.0232 - val_mean_absolute_error: 0.1122\n",
      "Epoch 3/100\n",
      "30321/30321 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1048\n",
      "New best model saved at epoch 3 with val_loss: 0.0183\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0211 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1048 - val_loss: 0.0183 - val_mean_squared_error: 0.0183 - val_mean_absolute_error: 0.0971\n",
      "Epoch 4/100\n",
      "30320/30321 [============================>.] - ETA: 0s - loss: 0.0175 - mean_squared_error: 0.0175 - mean_absolute_error: 0.0957\n",
      "New best model saved at epoch 4 with val_loss: 0.0159\n",
      "30321/30321 [==============================] - 113s 4ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - mean_absolute_error: 0.0957 - val_loss: 0.0159 - val_mean_squared_error: 0.0159 - val_mean_absolute_error: 0.0903\n",
      "Epoch 5/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0153 - mean_squared_error: 0.0153 - mean_absolute_error: 0.0896\n",
      "New best model saved at epoch 5 with val_loss: 0.0148\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - mean_absolute_error: 0.0896 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_mean_absolute_error: 0.0875\n",
      "Epoch 6/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0138 - mean_squared_error: 0.0138 - mean_absolute_error: 0.0850\n",
      "New best model saved at epoch 6 with val_loss: 0.0137\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - mean_absolute_error: 0.0850 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_mean_absolute_error: 0.0840\n",
      "Epoch 7/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0126 - mean_squared_error: 0.0126 - mean_absolute_error: 0.0812\n",
      "New best model saved at epoch 7 with val_loss: 0.0125\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - mean_absolute_error: 0.0812 - val_loss: 0.0125 - val_mean_squared_error: 0.0125 - val_mean_absolute_error: 0.0787\n",
      "Epoch 8/100\n",
      "30315/30321 [============================>.] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118 - mean_absolute_error: 0.0785\n",
      "New best model saved at epoch 8 with val_loss: 0.0118\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - mean_absolute_error: 0.0785 - val_loss: 0.0118 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0766\n",
      "Epoch 9/100\n",
      "30315/30321 [============================>.] - ETA: 0s - loss: 0.0111 - mean_squared_error: 0.0111 - mean_absolute_error: 0.0760\n",
      "New best model saved at epoch 9 with val_loss: 0.0114\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - mean_absolute_error: 0.0760 - val_loss: 0.0114 - val_mean_squared_error: 0.0114 - val_mean_absolute_error: 0.0757\n",
      "Epoch 10/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0105 - mean_squared_error: 0.0105 - mean_absolute_error: 0.0738\n",
      "Model saved at models_6/model_epoch_10.h5\n",
      "\n",
      "New best model saved at epoch 10 with val_loss: 0.0111\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - mean_absolute_error: 0.0738 - val_loss: 0.0111 - val_mean_squared_error: 0.0111 - val_mean_absolute_error: 0.0746\n",
      "Epoch 11/100\n",
      "30318/30321 [============================>.] - ETA: 0s - loss: 0.0100 - mean_squared_error: 0.0100 - mean_absolute_error: 0.0721\n",
      "New best model saved at epoch 11 with val_loss: 0.0104\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - mean_absolute_error: 0.0721 - val_loss: 0.0104 - val_mean_squared_error: 0.0104 - val_mean_absolute_error: 0.0719\n",
      "Epoch 12/100\n",
      "30318/30321 [============================>.] - ETA: 0s - loss: 0.0096 - mean_squared_error: 0.0096 - mean_absolute_error: 0.0706\n",
      "New best model saved at epoch 12 with val_loss: 0.0102\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - mean_absolute_error: 0.0706 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_mean_absolute_error: 0.0707\n",
      "Epoch 13/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - mean_absolute_error: 0.0692 - val_loss: 0.0102 - val_mean_squared_error: 0.0102 - val_mean_absolute_error: 0.0711\n",
      "Epoch 14/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0089 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0679\n",
      "New best model saved at epoch 14 with val_loss: 0.0096\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0679 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_mean_absolute_error: 0.0684\n",
      "Epoch 15/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0087 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0669\n",
      "New best model saved at epoch 15 with val_loss: 0.0096\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0669 - val_loss: 0.0096 - val_mean_squared_error: 0.0096 - val_mean_absolute_error: 0.0686\n",
      "Epoch 16/100\n",
      "30313/30321 [============================>.] - ETA: 0s - loss: 0.0084 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0657\n",
      "New best model saved at epoch 16 with val_loss: 0.0092\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0657 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_mean_absolute_error: 0.0668\n",
      "Epoch 17/100\n",
      "30315/30321 [============================>.] - ETA: 0s - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0649\n",
      "New best model saved at epoch 17 with val_loss: 0.0090\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0649 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_mean_absolute_error: 0.0659\n",
      "Epoch 18/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0640 - val_loss: 0.0095 - val_mean_squared_error: 0.0095 - val_mean_absolute_error: 0.0680\n",
      "Epoch 19/100\n",
      "30315/30321 [============================>.] - ETA: 0s - loss: 0.0077 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0631\n",
      "New best model saved at epoch 19 with val_loss: 0.0090\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0631 - val_loss: 0.0090 - val_mean_squared_error: 0.0090 - val_mean_absolute_error: 0.0665\n",
      "Epoch 20/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0076 - mean_squared_error: 0.0076 - mean_absolute_error: 0.0624\n",
      "Model saved at models_6/model_epoch_20.h5\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - mean_absolute_error: 0.0624 - val_loss: 0.0092 - val_mean_squared_error: 0.0092 - val_mean_absolute_error: 0.0679\n",
      "Epoch 21/100\n",
      "30316/30321 [============================>.] - ETA: 0s - loss: 0.0075 - mean_squared_error: 0.0075 - mean_absolute_error: 0.0619\n",
      "New best model saved at epoch 21 with val_loss: 0.0086\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - mean_absolute_error: 0.0619 - val_loss: 0.0086 - val_mean_squared_error: 0.0086 - val_mean_absolute_error: 0.0643\n",
      "Epoch 22/100\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - mean_absolute_error: 0.0613 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_mean_absolute_error: 0.0650\n",
      "Epoch 23/100\n",
      "30313/30321 [============================>.] - ETA: 0s - loss: 0.0072 - mean_squared_error: 0.0072 - mean_absolute_error: 0.0607\n",
      "New best model saved at epoch 23 with val_loss: 0.0084\n",
      "30321/30321 [==============================] - 109s 4ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - mean_absolute_error: 0.0607 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0632\n",
      "Epoch 24/100\n",
      "30321/30321 [==============================] - ETA: 0s - loss: 0.0071 - mean_squared_error: 0.0071 - mean_absolute_error: 0.0602\n",
      "New best model saved at epoch 24 with val_loss: 0.0084\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - mean_absolute_error: 0.0602 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0629\n",
      "Epoch 25/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - mean_absolute_error: 0.0597 - val_loss: 0.0086 - val_mean_squared_error: 0.0086 - val_mean_absolute_error: 0.0644\n",
      "Epoch 26/100\n",
      "30320/30321 [============================>.] - ETA: 0s - loss: 0.0069 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0593\n",
      "New best model saved at epoch 26 with val_loss: 0.0083\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - mean_absolute_error: 0.0593 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_mean_absolute_error: 0.0618\n",
      "Epoch 27/100\n",
      "30321/30321 [==============================] - ETA: 0s - loss: 0.0068 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0589\n",
      "New best model saved at epoch 27 with val_loss: 0.0081\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - mean_absolute_error: 0.0589 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_mean_absolute_error: 0.0615\n",
      "Epoch 28/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - mean_absolute_error: 0.0586 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_mean_absolute_error: 0.0631\n",
      "Epoch 29/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0582 - val_loss: 0.0085 - val_mean_squared_error: 0.0085 - val_mean_absolute_error: 0.0635\n",
      "Epoch 30/100\n",
      "30313/30321 [============================>.] - ETA: 0s - loss: 0.0066 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0580\n",
      "Model saved at models_6/model_epoch_30.h5\n",
      "\n",
      "New best model saved at epoch 30 with val_loss: 0.0079\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - mean_absolute_error: 0.0580 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0609\n",
      "Epoch 31/100\n",
      "30321/30321 [==============================] - 113s 4ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0577 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_mean_absolute_error: 0.0631\n",
      "Epoch 32/100\n",
      "30317/30321 [============================>.] - ETA: 0s - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0573\n",
      "New best model saved at epoch 32 with val_loss: 0.0079\n",
      "30321/30321 [==============================] - 113s 4ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - mean_absolute_error: 0.0573 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0605\n",
      "Epoch 33/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0571 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_mean_absolute_error: 0.0633\n",
      "Epoch 34/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - mean_absolute_error: 0.0567 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_mean_absolute_error: 0.0655\n",
      "Epoch 35/100\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - mean_absolute_error: 0.0565 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0613\n",
      "Epoch 36/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - mean_absolute_error: 0.0562 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_mean_absolute_error: 0.0610\n",
      "Epoch 37/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - mean_absolute_error: 0.0560 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_mean_absolute_error: 0.0607\n",
      "Epoch 38/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0062 - mean_squared_error: 0.0062 - mean_absolute_error: 0.0558\n",
      "New best model saved at epoch 38 with val_loss: 0.0079\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - mean_absolute_error: 0.0558 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0610\n",
      "Epoch 39/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0557\n",
      "New best model saved at epoch 39 with val_loss: 0.0078\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0557 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_mean_absolute_error: 0.0600\n",
      "Epoch 40/100\n",
      "30316/30321 [============================>.] - ETA: 0s - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0555\n",
      "Model saved at models_6/model_epoch_40.h5\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0555 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0608\n",
      "Epoch 41/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0554 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0605\n",
      "Epoch 42/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - mean_absolute_error: 0.0553 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0637\n",
      "Epoch 43/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0551 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_mean_absolute_error: 0.0598\n",
      "Epoch 44/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0549 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0606\n",
      "Epoch 45/100\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - mean_absolute_error: 0.0548 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_mean_absolute_error: 0.0633\n",
      "Epoch 46/100\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0546 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_mean_absolute_error: 0.0600\n",
      "Epoch 47/100\n",
      "30318/30321 [============================>.] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0544\n",
      "New best model saved at epoch 47 with val_loss: 0.0077\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0544 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_mean_absolute_error: 0.0600\n",
      "Epoch 48/100\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0543 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0605\n",
      "Epoch 49/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - mean_absolute_error: 0.0541 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_mean_absolute_error: 0.0617\n",
      "Epoch 50/100\n",
      "30321/30321 [==============================] - ETA: 0s - loss: 0.0059 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0543\n",
      "Model saved at models_6/model_epoch_50.h5\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - mean_absolute_error: 0.0543 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_mean_absolute_error: 0.0598\n",
      "Epoch 51/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - mean_absolute_error: 0.0540 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0638\n",
      "Epoch 52/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - mean_absolute_error: 0.0539 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0612\n",
      "Epoch 53/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0536 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_mean_absolute_error: 0.0592\n",
      "Epoch 54/100\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - mean_absolute_error: 0.0537 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_mean_absolute_error: 0.0603\n",
      "Epoch 55/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0536 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_mean_absolute_error: 0.0602\n",
      "Epoch 56/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0536 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0605\n",
      "Epoch 57/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0535\n",
      "New best model saved at epoch 57 with val_loss: 0.0077\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0535 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_mean_absolute_error: 0.0591\n",
      "Epoch 58/100\n",
      "30314/30321 [============================>.] - ETA: 0s - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0534\n",
      "New best model saved at epoch 58 with val_loss: 0.0077\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0534 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_mean_absolute_error: 0.0589\n",
      "Epoch 59/100\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0532 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0636\n",
      "Epoch 60/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0533\n",
      "Model saved at models_6/model_epoch_60.h5\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0533 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_mean_absolute_error: 0.0621\n",
      "Epoch 61/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0532 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0639\n",
      "Epoch 62/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0532 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_mean_absolute_error: 0.0605\n",
      "Epoch 63/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0532 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_mean_absolute_error: 0.0619\n",
      "Epoch 64/100\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0531 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0635\n",
      "Epoch 65/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_mean_absolute_error: 0.0591\n",
      "Epoch 66/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0077 - val_mean_squared_error: 0.0077 - val_mean_absolute_error: 0.0594\n",
      "Epoch 67/100\n",
      "30312/30321 [============================>.] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530\n",
      "New best model saved at epoch 67 with val_loss: 0.0076\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0076 - val_mean_squared_error: 0.0076 - val_mean_absolute_error: 0.0586\n",
      "Epoch 68/100\n",
      "30321/30321 [==============================] - 111s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0598\n",
      "Epoch 69/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_mean_absolute_error: 0.0619\n",
      "Epoch 70/100\n",
      "30311/30321 [============================>.] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530\n",
      "Model saved at models_6/model_epoch_70.h5\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0597\n",
      "Epoch 71/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_mean_absolute_error: 0.0615\n",
      "Epoch 72/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0528 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_mean_absolute_error: 0.0592\n",
      "Epoch 73/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0078 - val_mean_squared_error: 0.0078 - val_mean_absolute_error: 0.0595\n",
      "Epoch 74/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0093 - val_mean_squared_error: 0.0093 - val_mean_absolute_error: 0.0690\n",
      "Epoch 75/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0597\n",
      "Epoch 76/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_mean_absolute_error: 0.0624\n",
      "Epoch 77/100\n",
      "30321/30321 [==============================] - 110s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_mean_absolute_error: 0.0601\n",
      "Epoch 78/100\n",
      "30321/30321 [==============================] - 113s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_mean_absolute_error: 0.0613\n",
      "Epoch 79/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_mean_absolute_error: 0.0613\n",
      "Epoch 80/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0528\n",
      "Model saved at models_6/model_epoch_80.h5\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0528 - val_loss: 0.0083 - val_mean_squared_error: 0.0083 - val_mean_absolute_error: 0.0623\n",
      "Epoch 81/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0528 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_mean_absolute_error: 0.0601\n",
      "Epoch 82/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0599\n",
      "Epoch 83/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0631\n",
      "Epoch 84/100\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0528 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_mean_absolute_error: 0.0600\n",
      "Epoch 85/100\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_mean_absolute_error: 0.0604\n",
      "Epoch 86/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_mean_absolute_error: 0.0617\n",
      "Epoch 87/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0596\n",
      "Epoch 88/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_mean_absolute_error: 0.0607\n",
      "Epoch 89/100\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0531 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_mean_absolute_error: 0.0619\n",
      "Epoch 90/100\n",
      "30319/30321 [============================>.] - ETA: 0s - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530\n",
      "Model saved at models_6/model_epoch_90.h5\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0630\n",
      "Epoch 91/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_mean_absolute_error: 0.0613\n",
      "Epoch 92/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0084 - val_mean_squared_error: 0.0084 - val_mean_absolute_error: 0.0632\n",
      "Epoch 93/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_mean_absolute_error: 0.0617\n",
      "Epoch 94/100\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0529 - val_loss: 0.0087 - val_mean_squared_error: 0.0087 - val_mean_absolute_error: 0.0643\n",
      "Epoch 95/100\n",
      "30321/30321 [==============================] - 115s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0080 - val_mean_squared_error: 0.0080 - val_mean_absolute_error: 0.0595\n",
      "Epoch 96/100\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_mean_absolute_error: 0.0614\n",
      "Epoch 97/100\n",
      "30321/30321 [==============================] - 112s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0530 - val_loss: 0.0079 - val_mean_squared_error: 0.0079 - val_mean_absolute_error: 0.0591\n",
      "Epoch 98/100\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0531 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_mean_absolute_error: 0.0600\n",
      "Epoch 99/100\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - mean_absolute_error: 0.0531 - val_loss: 0.0082 - val_mean_squared_error: 0.0082 - val_mean_absolute_error: 0.0610\n",
      "Epoch 100/100\n",
      "30316/30321 [============================>.] - ETA: 0s - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0531\n",
      "Model saved at models_6/model_epoch_100.h5\n",
      "30321/30321 [==============================] - 114s 4ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - mean_absolute_error: 0.0531 - val_loss: 0.0081 - val_mean_squared_error: 0.0081 - val_mean_absolute_error: 0.0605\n",
      "7581/7581 [==============================] - 14s 2ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0605\n",
      "Test Loss: 0.0081\n",
      "Test MSE: 0.0081\n",
      "Test MAE: 0.0605\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('') # for chess import - removed for privacy\n",
    "import chess\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import joblib\n",
    "\n",
    "# Prepare the parameters\n",
    "parameter_columns = [\n",
    "    'turn_number', 'elo_diff', 'piece_diff', 'mobility', 'king_safety',\n",
    "    'control_of_key_squares', 'opening', 'middle_game', 'endgame',\n",
    "    'doubled_pawns_diff', 'isolated_pawns_diff'\n",
    "]\n",
    "X_params = game_states[parameter_columns].fillna(0).astype(np.float32).to_numpy()\n",
    "\n",
    "# Split X_params into separate arrays for processing\n",
    "# turn_number = X_params[:, 0].reshape(-1, 1)  # Extract `turn_number`\n",
    "# elo_diff = X_params[:, 1].reshape(-1, 1)  # Extract `elo_diff`\n",
    "# piece_diff = X_params[:, 2].reshape(-1, 1)  # Extract `piece_diff`\n",
    "# king_safety = X_params[:, 3].reshape(-1, 1)  # Extract `king_safety`\n",
    "# doubled_pawns_diff = X_params[:, 9].reshape(-1, 1)  # Extract `doubled_pawns_diff`\n",
    "# isolated_pawns_diff = X_params[:, 10].reshape(-1, 1)  # Extract `isolated_pawns_diff`\n",
    "\n",
    "# Binary columns: No transformation needed\n",
    "# binary_features = X_params[:, 6:9]  # `opening`, `middle_game`, `endgame`\n",
    "\n",
    "# Prepare the target variable\n",
    "y = game_states['y'].astype(np.float32).to_numpy()\n",
    "\n",
    "# Split the data\n",
    "X_board_train, X_board_test, X_params_train, X_params_test, y_train, y_test = train_test_split(\n",
    "    X_board, X_params, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train data scaling\n",
    "turn_number_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "turn_number = X_params_train[:, 0].reshape(-1, 1)  # `turn_number`\n",
    "elo_diff = X_params_train[:, 1].reshape(-1, 1)  # `elo_diff`\n",
    "piece_diff = X_params_train[:, 2].reshape(-1, 1)  # `piece_diff`\n",
    "mobility = X_params_train[:, 3].reshape(-1, 1) # 'mobility'\n",
    "king_safety = X_params_train[:, 4].reshape(-1, 1)  # `king_safety`\n",
    "control_of_key_squares = X_params_train[:, 5].reshape(-1, 1)  # `control_of_key_squares`S\n",
    "binary_features = X_params_train[:, 6:9] # `opening`, `middle_game`, `endgame`\n",
    "doubled_pawns_diff = X_params_train[:, 9].reshape(-1, 1)  # `doubled_pawns_diff`\n",
    "isolated_pawns_diff = X_params_train[:, 10].reshape(-1, 1)  # `isolated_pawns_diff`\n",
    "\n",
    "# Fit the scalers\n",
    "turn_number_scaler.fit(turn_number)\n",
    "features_to_scale_train = np.hstack([\n",
    "    elo_diff,\n",
    "    piece_diff,\n",
    "    mobility,\n",
    "    king_safety,\n",
    "    control_of_key_squares,\n",
    "    doubled_pawns_diff,\n",
    "    isolated_pawns_diff\n",
    "])\n",
    "standard_scaler.fit(features_to_scale_train)\n",
    "\n",
    "# Save the scalers IMPORTANT FOR TEST AND ACTUAL PROGRAM\n",
    "joblib.dump(turn_number_scaler, 'turn_number_scaler.save')\n",
    "joblib.dump(standard_scaler, 'standard_scaler.save')\n",
    "\n",
    "# Transform training data\n",
    "turn_number_scaled_train = turn_number_scaler.transform(turn_number)\n",
    "features_scaled_train = standard_scaler.transform(features_to_scale_train)\n",
    "\n",
    "# Extract scaled features\n",
    "elo_diff_scaled_train = features_scaled_train[:, 0].reshape(-1, 1)\n",
    "piece_diff_scaled_train = features_scaled_train[:, 1].reshape(-1, 1)\n",
    "mobility_scaled_train = features_scaled_train[:, 2].reshape(-1, 1)\n",
    "king_safety_scaled_train = features_scaled_train[:, 3].reshape(-1, 1)\n",
    "control_of_key_squares_scaled_train = features_scaled_train[:, 4].reshape(-1, 1)\n",
    "doubled_pawns_diff_scaled_train = features_scaled_train[:, 5].reshape(-1, 1)\n",
    "isolated_pawns_diff_scaled_train = features_scaled_train[:, 6].reshape(-1, 1)\n",
    "\n",
    "X_params_train_scaled = np.hstack([\n",
    "    turn_number_scaled_train,\n",
    "    elo_diff_scaled_train,\n",
    "    piece_diff_scaled_train,\n",
    "    mobility_scaled_train,\n",
    "    king_safety_scaled_train,\n",
    "    control_of_key_squares_scaled_train,\n",
    "    X_params_train[:, 6:9],  # Binary features\n",
    "    doubled_pawns_diff_scaled_train,\n",
    "    isolated_pawns_diff_scaled_train\n",
    "])\n",
    "\n",
    "# Prepare validation data features\n",
    "elo_diff_test = X_params_test[:, 1].reshape(-1, 1)\n",
    "piece_diff_test = X_params_test[:, 2].reshape(-1, 1)\n",
    "mobility_test = X_params_test[:, 3].reshape(-1, 1)\n",
    "king_safety_test = X_params_test[:, 4].reshape(-1, 1)\n",
    "control_of_key_squares_test = X_params_test[:, 5].reshape(-1, 1)\n",
    "doubled_pawns_diff_test = X_params_test[:, 9].reshape(-1, 1)\n",
    "isolated_pawns_diff_test = X_params_test[:, 10].reshape(-1, 1)\n",
    "\n",
    "features_to_scale_test = np.hstack([\n",
    "    elo_diff_test,\n",
    "    piece_diff_test,\n",
    "    mobility_test,\n",
    "    king_safety_test,\n",
    "    control_of_key_squares_test,\n",
    "    doubled_pawns_diff_test,\n",
    "    isolated_pawns_diff_test\n",
    "])\n",
    "\n",
    "# Transform validation data using the same scaler\n",
    "turn_number_test = X_params_test[:, 0].reshape(-1, 1)\n",
    "turn_number_scaled_test = turn_number_scaler.transform(turn_number_test)\n",
    "features_scaled_test = standard_scaler.transform(features_to_scale_test)\n",
    "\n",
    "# Extract scaled features\n",
    "elo_diff_scaled_test = features_scaled_test[:, 0].reshape(-1, 1)\n",
    "piece_diff_scaled_test = features_scaled_test[:, 1].reshape(-1, 1)\n",
    "mobility_scaled_test = features_scaled_test[:, 2].reshape(-1, 1)\n",
    "king_safety_scaled_test = features_scaled_test[:, 3].reshape(-1, 1)\n",
    "control_of_key_squares_scaled_test = features_scaled_test[:, 4].reshape(-1, 1)\n",
    "doubled_pawns_diff_scaled_test = features_scaled_test[:, 5].reshape(-1, 1)\n",
    "isolated_pawns_diff_scaled_test = features_scaled_test[:, 6].reshape(-1, 1)\n",
    "\n",
    "X_params_test_scaled = np.hstack([\n",
    "    turn_number_scaled_test,\n",
    "    elo_diff_scaled_test,\n",
    "    piece_diff_scaled_test,\n",
    "    mobility_scaled_test,\n",
    "    king_safety_scaled_test,\n",
    "    control_of_key_squares_scaled_test,\n",
    "    X_params_test[:, 6:9],  # Binary features\n",
    "    doubled_pawns_diff_scaled_test,\n",
    "    isolated_pawns_diff_scaled_test\n",
    "])\n",
    "\n",
    "# Define the CNN model\n",
    "def create_cnn_model():\n",
    "    board_input = Input(shape=(8, 8, 12), name='board_input')\n",
    "    x = Conv2D(64, kernel_size=3, activation='relu', padding='same')(board_input)\n",
    "    x = Conv2D(128, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    return board_input, x\n",
    "\n",
    "# Define the parameters model\n",
    "def create_params_model(input_shape):\n",
    "    params_input = Input(shape=input_shape, name='params_input')\n",
    "    y = Dense(64, activation='relu')(params_input)\n",
    "    y = Dense(64, activation='relu')(y)\n",
    "    return params_input, y\n",
    "\n",
    "# Create models and combine\n",
    "board_input, board_output = create_cnn_model()\n",
    "params_input, params_output = create_params_model((X_params.shape[1],))\n",
    "combined = Concatenate()([board_output, params_output])\n",
    "z = Dense(64, activation='relu')(combined)\n",
    "z = Dense(1, activation='linear')(z)\n",
    "model = Model(inputs=[board_input, params_input], outputs=z)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_squared_error', 'mean_absolute_error'] \n",
    ")\n",
    "\n",
    "# Define model save directory\n",
    "model_save_dir = 'models_6'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Custom callback to save model every 10 epochs and save the best model\n",
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, save_every_n_epochs, model_save_dir):\n",
    "        super(CustomModelCheckpoint, self).__init__()\n",
    "        self.save_every_n_epochs = save_every_n_epochs\n",
    "        self.model_save_dir = model_save_dir\n",
    "        self.best_val_loss = float('inf')\n",
    "        os.makedirs(self.model_save_dir, exist_ok=True) \n",
    "        self.best_model_path = os.path.join(self.model_save_dir, 'best_model.h5') \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        # Save the model every N epochs\n",
    "        if (epoch + 1) % self.save_every_n_epochs == 0:\n",
    "            model_path = os.path.join(self.model_save_dir, f'model_epoch_{epoch + 1}.h5')\n",
    "            self.model.save(model_path)\n",
    "            print(f'\\nModel saved at {model_path}')\n",
    "\n",
    "        # Save the best model based on validation loss\n",
    "        current_val_loss = logs.get('val_loss')\n",
    "        if current_val_loss is not None and current_val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = current_val_loss\n",
    "            self.model.save(self.best_model_path)\n",
    "            print(f'\\nNew best model saved at epoch {epoch + 1} with val_loss: {current_val_loss:.4f}')\n",
    "\n",
    "# Instantiate the custom callback\n",
    "save_every_n_epochs = 10\n",
    "custom_checkpoint = CustomModelCheckpoint(save_every_n_epochs, model_save_dir)\n",
    "\n",
    "# Custom callback 2: Save model logs in CSV\n",
    "class CSVLoggerCallback(Callback):\n",
    "    def __init__(self, file_path):\n",
    "        super().__init__()\n",
    "        self.file_path = file_path\n",
    "        self.file_initialized = False\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        row = {'epoch': epoch + 1, **logs}  # Include epoch and metrics\n",
    "\n",
    "        # Write to CSV file\n",
    "        if not self.file_initialized:\n",
    "            # Write header if file doesn't exist or for the first time\n",
    "            with open(self.file_path, 'w', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=row.keys())\n",
    "                writer.writeheader()\n",
    "                writer.writerow(row)\n",
    "            self.file_initialized = True\n",
    "        else:\n",
    "            # Append rows for subsequent epochs\n",
    "            with open(self.file_path, 'a', newline='') as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=row.keys())\n",
    "                writer.writerow(row)\n",
    "\n",
    "# Define the callback\n",
    "csv_logger = CSVLoggerCallback('training_history_6.csv')\n",
    "\n",
    "# Train the model with the custom callback\n",
    "history = model.fit(\n",
    "    [X_board_train, X_params_train_scaled],\n",
    "    y_train,\n",
    "    validation_data=([X_board_test, X_params_test_scaled], y_test),\n",
    "    epochs=100, \n",
    "    batch_size=32,\n",
    "    callbacks=[custom_checkpoint, csv_logger]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_mse, test_mae = model.evaluate([X_board_test, X_params_test_scaled], y_test)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")\n",
    "\n",
    "# Plot training history on a logarithmic scale and save the plot as an image\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(history.history['loss'], label='Train MSE')\n",
    "plt.plot(history.history['val_loss'], label='Validation MSE')\n",
    "plt.title('Model Mean Squared Error')\n",
    "plt.ylabel('MSE (Log Scale)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.yscale('log')  # Set y-axis to log scale\n",
    "plt.legend()\n",
    "plt.savefig('train_history_6.png') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Analysis\n",
    "\n",
    "The below plot shows the training and validation Mean Squared Error (MSE) over 100 epochs, with a log scale used for the MSE axis.\n",
    "\n",
    "Both the training MSE (blue line) and validation MSE (orange line) decrease significantly during the initial epochs, indicating that the model learns effectively in the early phase.\n",
    "After about 20 epochs, the training MSE continues to decrease smoothly, while the validation MSE starts to stabilize with some fluctuations.\n",
    "\n",
    "The validation MSE initially tracks the training MSE closely, showing good generalization at the start.\n",
    "Beyond around epoch 40, the validation MSE shows more noise and fluctuates, suggesting some overfitting. Despite this, the overall validation performance remains stable.\n",
    "\n",
    "The training MSE converges to a very low value, indicating the model fits the training data well.\n",
    "The validation MSE stabilizes at a slightly higher value compared to the training MSE, which is typical in machine learning due to differences in the distributions of the training and validation datasets.\n",
    "\n",
    "Overall, our best model during the training had a validation loss MSE of 0.0079, which, in our case, corresponds to around a 9% average error when predicting probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image as PILImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_name = 'train_history_6.png'\n",
    "img = PILImage.open(file_name)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Model Usage\n",
    "Now, one can use our best model to predict winning percentage (white) given a standard chess board FEN notation. Given our validation error, this estimate will likely be within 8% of the actual value. \n",
    "\n",
    "This program can be run from another seperate file by loading the model saved above, or by directly running the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import chess\n",
    "import chess.svg\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "# Function to calculate all parameters\n",
    "def calculate_parameters(board, turn_number, elo_diff=0):\n",
    "    piece_diff = calculate_piece_differential(board)\n",
    "    mobility = calculate_mobility(board)\n",
    "    king_safety = calculate_king_safety(board)\n",
    "    control_of_key_squares = calculate_control_of_key_squares(board)\n",
    "    game_phase = get_game_phase(turn_number)\n",
    "    pawn_structure = calculate_pawn_structure(board)\n",
    "\n",
    "    params = {\n",
    "        'turn_number': turn_number,\n",
    "        'elo_diff': elo_diff,\n",
    "        'piece_diff': piece_diff,\n",
    "        'mobility': mobility,\n",
    "        'king_safety': king_safety,\n",
    "        'control_of_key_squares': control_of_key_squares,\n",
    "        'doubled_pawns_diff': pawn_structure['doubled_pawns_diff'],\n",
    "        'isolated_pawns_diff': pawn_structure['isolated_pawns_diff'],\n",
    "        'opening': game_phase['opening'],\n",
    "        'middle_game': game_phase['middle_game'],\n",
    "        'endgame': game_phase['endgame']\n",
    "    }\n",
    "    return params\n",
    "\n",
    "# Function to ensure all probability are between 0 and 1.\n",
    "def warp_probability(predicted_y, k=10):\n",
    "    \"\"\"\n",
    "    Warp the predicted probability to be between (0, 1) exclusive, while preserving\n",
    "    values near 0.5 and warping values closer to 0 and 1.\n",
    "    \n",
    "    Parameters:\n",
    "        predicted_y (float): The raw predicted probability.\n",
    "        k (float): The steepness of the warp effect. Default is 10.\n",
    "    \n",
    "    Returns:\n",
    "        float: Warped probability.\n",
    "    \"\"\"\n",
    "    raw_prob = predicted_y[0][0]\n",
    "    warped_prob = 1 / (1 + np.exp(-k * (raw_prob - 0.5)))\n",
    "    return warped_prob\n",
    "\n",
    "def print_chess_board(fen, blank_square=\"▢\"):\n",
    "    # Split the FEN string into board and additional information \n",
    "    board_part = fen.split()[0]\n",
    "    rows = board_part.split(\"/\")\n",
    "    \n",
    "    # Define piece symbols\n",
    "    piece_symbols = {\n",
    "        \"p\": \"♟\", \"r\": \"♜\", \"n\": \"♞\", \"b\": \"♝\", \"q\": \"♛\", \"k\": \"♚\",\n",
    "        \"P\": \"♙\", \"R\": \"♖\", \"N\": \"♘\", \"B\": \"♗\", \"Q\": \"♕\", \"K\": \"♔\",\n",
    "    }\n",
    "    \n",
    "    # Convert FEN rows into a 2D list of board characters\n",
    "    board = []\n",
    "    for row in rows:\n",
    "        board_row = []\n",
    "        for char in row:\n",
    "            if char.isdigit():\n",
    "                # Add empty squares with the custom blank_square character\n",
    "                board_row.extend([blank_square] * int(char))\n",
    "            else:\n",
    "                # Add piece\n",
    "                board_row.append(piece_symbols.get(char, char))\n",
    "        board.append(board_row)\n",
    "    \n",
    "    # Print the board\n",
    "    print(\"  a b c d e f g h\")\n",
    "    for i, row in enumerate(reversed(board)):\n",
    "        print(f\"{8-i} {' '.join(row)} {8-i}\")\n",
    "    print(\"  a b c d e f g h\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from used_models/best_model_1.h5\n",
      "\n",
      "Input parameters:\n",
      "FEN: r2qkb1r/p1p1pp2/bpn3pn/3p3p/4PB2/3P1N2/PPP2PPP/RN1QKB1R w KQkq - 0 1\n",
      "Turn number:55\n",
      "ELO diff:20.0\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "\n",
      "Predicted Win Probability for White: 37.31%\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"350\" height=\"350\"><desc><pre>r . . q k b . r\n",
       "p . p . p p . .\n",
       "b p n . . . p n\n",
       ". . . p . . . p\n",
       ". . . . P B . .\n",
       ". . . P . N . .\n",
       "P P P . . P P P\n",
       "R N . Q K B . R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 240)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(240, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 195)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 150)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 150)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(15, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(105, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(330, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>"
      ],
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"350\" height=\"350\"><desc><pre>r . . q k b . r\n",
       "p . p . p p . .\n",
       "b p n . . . p n\n",
       ". . . p . . . p\n",
       ". . . . P B . .\n",
       ". . . P . N . .\n",
       "P P P . . P P P\n",
       "R N . Q K B . R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 240)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(240, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 195)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 150)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 150)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(15, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(105, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(330, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>"
      ],
      "text/plain": [
       "'<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"350\" height=\"350\"><desc><pre>r . . q k b . r\\np . p . p p . .\\nb p n . . . p n\\n. . . p . . . p\\n. . . . P B . .\\n. . . P . N . .\\nP P P . . P P P\\nR N . Q K B . R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 240)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(240, 240)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 195)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 150)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 150)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(15, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(105, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(330, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results program: load in the model path, as well as parameters right below. \n",
    "\n",
    "model_path = 'used_models/best_model_1.h5'  \n",
    "input_fen = 'r2qkb1r/p1p1pp2/bpn3pn/3p3p/4PB2/3P1N2/PPP2PPP/RN1QKB1R w KQkq - 0 1'\n",
    "input_turn_num = '55' # default 55 if left empty\n",
    "input_elo_diff = '20' # default 0 if left empty\n",
    "\n",
    "\n",
    "try:\n",
    "    model = load_model(model_path, compile=False)\n",
    "    print(f\"Model loaded from {model_path}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Prompt the user for FEN notation\n",
    "fen = input_fen.strip()\n",
    "try:\n",
    "    board = chess.Board(fen)\n",
    "except ValueError as e:\n",
    "    print(f\"Invalid FEN notation: {e}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print('Input parameters:')\n",
    "print('FEN: ' + fen)\n",
    "\n",
    "# Check for the initial position\n",
    "if board.board_fen() == chess.STARTING_BOARD_FEN:\n",
    "    print(\"\\nPredicted Win Probability for White: 50.00%\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# Prompt the user for move count (turn number), default to 55 if not provided\n",
    "turn_number_input = input_turn_num.strip()\n",
    "if turn_number_input == '':\n",
    "    turn_number = 55\n",
    "else:\n",
    "    try:\n",
    "        turn_number = int(turn_number_input)\n",
    "    except ValueError:\n",
    "        print(\"Invalid move count. Please enter an integer.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "print(f'Turn number:{turn_number}')      \n",
    "\n",
    "# Prompt the user for Elo difference, default to 0 if not provided\n",
    "elo_diff_input = input_elo_diff.strip()\n",
    "if elo_diff_input == '':\n",
    "    elo_diff = 0\n",
    "else:\n",
    "    try:\n",
    "        elo_diff = float(elo_diff_input)\n",
    "    except ValueError:\n",
    "        print(\"Invalid Elo difference. Please enter a number.\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "print(f'ELO diff:{elo_diff}') \n",
    "\n",
    "# Convert FEN to tensor\n",
    "board_tensor = fen_to_tensor(fen)\n",
    "X_board_input = np.expand_dims(board_tensor, axis=0)  # Add batch dimension\n",
    "\n",
    "# Calculate parameters\n",
    "params = calculate_parameters(board, turn_number, elo_diff)\n",
    "\n",
    "# Prepare parameters for model input\n",
    "parameter_columns = [\n",
    "    'turn_number', 'elo_diff', 'piece_diff', 'mobility', 'king_safety',\n",
    "    'control_of_key_squares', 'opening', 'middle_game', 'endgame',\n",
    "    'doubled_pawns_diff', 'isolated_pawns_diff'\n",
    "]\n",
    "params_list = [params[col] for col in parameter_columns]\n",
    "X_params_input = np.array([params_list], dtype=np.float32)\n",
    "\n",
    "# Predict the win probability\n",
    "predicted_y = model.predict([X_board_input, X_params_input])\n",
    "predicted_win_probability = predicted_y[0][0]\n",
    "predicted_win_probability = warp_probability(predicted_y)\n",
    "\n",
    "print(f\"\\nPredicted Win Probability for White: {predicted_win_probability * 100:.2f}%\\n\")\n",
    "# Output the board\n",
    "board = chess.Board(fen)\n",
    "chess.svg.board(board, size=350)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Tensorflow 2.13.0",
   "language": "python",
   "name": "tensorflow-2.13.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
